{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL III : Decision Trees and Random forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and modules\n",
    "\n",
    "# Import the necessary libraries\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project directory to the sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "# Import everything from lib_import.py, evaluate.py, data_preprocessing.py \n",
    "from lib.lib_import import *\n",
    "from src.data_preprocessing import *\n",
    "from src.evaluate import *\n",
    "\n",
    "# Import the data\n",
    "from data.data_extract import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "\n",
    "df_data = load_data()\n",
    "df_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_data.copy()\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic preprocessing : Fix target + remove inutil columns + drop outliers\n",
    "data = preprocess(data)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separating dataset - train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate the data into train and test\n",
    "df_train, df_test = seperate_train_test(data, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of target variable in training data\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.pie(df_train['>50K'].value_counts(), autopct='%1.1f%%')\n",
    "plt.legend(['<=50K', '>50K'], loc='upper right')\n",
    "plt.title('Distribution of target variable in training data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of target variable in test data\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.pie(df_test['>50K'].value_counts(), autopct='%1.1f%%')\n",
    "plt.legend(['<=50K', '>50K'], loc='upper right')\n",
    "plt.title('Distribution of target variable in training data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate the categorical and numerical variables\n",
    "cat_features = get_cat_features(data)\n",
    "cont_features = get_cont_features(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = msno.bar(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute the missing values in the categorical variables\n",
    "imput_cont = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imput_cat = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "\n",
    "# on n'impute pas pour les variables numériques car aucune n'est manquante. \n",
    "# for feature in cont_features :\n",
    "#     df_train[feature] = imput_cont.fit_transform(df_train[feature].values.reshape(-1,1)).ravel()\n",
    "#     df_test[feature] = imput_cont.transform(df_test[feature].values.reshape(-1,1)).ravel()\n",
    "    \n",
    "for feature in cat_features :\n",
    "    df_train[feature] = imput_cat.fit_transform(df_train[feature].values.reshape(-1,1)).ravel()\n",
    "    df_test[feature] = imput_cat.transform(df_test[feature].values.reshape(-1,1)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = msno.bar(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regrouping features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Values not referenced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['workclass'] = df_train['workclass'].replace({'?': 'Not referenced'})\n",
    "df_test['workclass'] = df_test['workclass'].replace({'?': 'Not referenced'})\n",
    "\n",
    "df_train['native-country'] = df_train['native-country'].replace({'?': 'Not referenced'})\n",
    "df_test['native-country'] = df_test['native-country'].replace({'?': 'Not referenced'})\n",
    "\n",
    "df_train['occupation'] = df_train['occupation'].replace({'?': 'Not referenced'})\n",
    "df_test['occupation'] = df_test['occupation'].replace({'?': 'Not referenced'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regroup 'Without-pay' and 'Never-worked' to 'No revenu'\n",
    "df_train['workclass'] = df_train['workclass'].replace({'Without-pay': 'No revenu', 'Never-worked': 'No revenu'})\n",
    "df_test['workclass'] = df_test['workclass'].replace({'Without-pay': 'No revenu', 'Never-worked': 'No revenu'})\n",
    "\n",
    "# Regrouper 'Self-emp-not-inc' and 'Self-emp-inc' to 'Self-emp'\n",
    "df_train['workclass'] = df_train['workclass'].replace({'Self-emp-not-inc': 'Self-emp', 'Self-emp-inc': 'Self-emp'})\n",
    "df_test['workclass'] = df_test['workclass'].replace({'Self-emp-not-inc': 'Self-emp', 'Self-emp-inc': 'Self-emp'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[df_train['workclass'] == 'Self-emp'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marital-status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['marital-status'] = df_train['marital-status'].replace({'Divorced': 'Now Single', 'Separated': 'Now Single', 'Widowed': 'Now Single'})\n",
    "df_test['marital-status'] = df_test['marital-status'].replace({'Divorced': 'Now Single', 'Separated': 'Now Single', 'Widowed': 'Now Single'})\n",
    "\n",
    "df_train['marital-status'] = df_train['marital-status'].replace({'Married-civ-spouse': 'Married', 'Married-AF-spouse': 'Married'})\n",
    "df_test['marital-status'] = df_test['marital-status'].replace({'Married-civ-spouse': 'Married', 'Married-AF-spouse': 'Married'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['relationship'] = df_train['relationship'].replace({'Husband': 'Married', 'Wife': 'Married'})\n",
    "df_test['relationship'] = df_test['relationship'].replace({'Husband': 'Married', 'Wife': 'Married'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['race'] = df_train['race'].replace({'Amer-Indian-Eskimo': 'Other'})\n",
    "df_test['race'] = df_test['race'].replace({'Amer-Indian-Eskimo': 'Other'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Native-country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each value of the 'native-country' variable, we calculate the number of individuals who have this value\n",
    "filtered = df_train[df_train['native-country'] != 'United-States']\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "filtered['native-country'].value_counts().plot(kind='bar')\n",
    "plt.title('Histogram of the native-country variable')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On met dans la catégorie \"Other\" tous les pays qui obtiennent un nombre d'observations inférieur à 200. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting for each value of the variable 'native-country' the number of individuals who have this value\n",
    "filtered = df_train[df_train['native-country'] != 'United-States']\n",
    "\n",
    "for country in filtered['native-country'].unique():\n",
    "    nb_samples_associated = filtered[filtered['native-country'] == country].shape[0]\n",
    "    if nb_samples_associated < 200:\n",
    "        df_train['native-country'] = df_train['native-country'].replace({country: 'Other'})\n",
    "        df_test['native-country'] = df_test['native-country'].replace({country: 'Other'})\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of the categorical variables\n",
    "df_train_categ = df_train.select_dtypes(include='object')\n",
    "\n",
    "plt.figure(figsize=(18, 18))\n",
    "for i, feature in enumerate(df_train_categ.columns):\n",
    "    if i <= 7:\n",
    "        ax = plt.subplot(4, 2, i + 1)\n",
    "        hist = sns.histplot(df_train[feature], ax=ax)\n",
    "        \n",
    "        if i == 7:  # Si c'est le dernier graphique, afficher uniquement la valeur la plus élevée car sinon illisible\n",
    "            max_height = 0\n",
    "            max_p = None\n",
    "            for p in hist.patches:\n",
    "                height = p.get_height()\n",
    "                if height > max_height:\n",
    "                    max_height = height\n",
    "                    max_p = p\n",
    "            if max_p is not None:\n",
    "                ax.annotate(f'{max_height:.0f}',\n",
    "                            xy=(max_p.get_x() + max_p.get_width() / 2, max_height),\n",
    "                            xytext=(0, 5),  # Décalage vertical de 5 points\n",
    "                            textcoords=\"offset points\",\n",
    "                            ha='center', va='bottom', fontsize=10, color='black')\n",
    "        else:  # Pour les autres graphiques, afficher toutes les valeurs\n",
    "            for p in hist.patches:\n",
    "                height = p.get_height()\n",
    "                ax.annotate(f'{height:.0f}',\n",
    "                            xy=(p.get_x() + p.get_width() / 2, height),\n",
    "                            xytext=(0, 5),  # Décalage vertical de 5 points\n",
    "                            textcoords=\"offset points\",\n",
    "                            ha='center', va='bottom', fontsize=10, color='black')\n",
    "        \n",
    "        ax.set_xlabel(feature, fontsize=20)\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Df_train, Df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the features and target variable\n",
    "X_train = df_train.drop('>50K', axis=1)\n",
    "y_train = df_train['>50K']\n",
    "\n",
    "X_test = df_test.drop('>50K', axis=1)\n",
    "y_test = df_test['>50K']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate Categorical and numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate the categorical and numerical variables\n",
    "cat_features = df_train.select_dtypes('object').columns\n",
    "cat_features.append(pd.Index(['education-num']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_features = df_train.select_dtypes('int64').columns\n",
    "cont_features = cont_features.drop('education-num')\n",
    "cont_features = cont_features.drop('>50K')\n",
    "cont_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Scaler\n",
    "\n",
    "scale_standard = StandardScaler() \n",
    "\n",
    "print('Categorical features : ', cont_features)\n",
    "for feature in cont_features:\n",
    "\n",
    "    # Normaliser les données d'entrainement\n",
    "    X_train[feature] = scale_standard.fit_transform(X_train[feature].values.reshape(-1,1)) \n",
    "    X_train[feature] = X_train[feature].ravel()\n",
    "\n",
    "    # Normaliser les données \n",
    "    X_test[feature] = scale_standard.transform(X_test[feature].values.reshape(-1,1))\n",
    "    X_test[feature] = X_test[feature].ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "X_train_LEncoder = X_train.copy()\n",
    "X_test_LEncoder = X_test.copy()\n",
    "\n",
    "for feature in cat_features:\n",
    "    X_train_LEncoder[feature] = label_encoder.fit_transform(X_train_LEncoder[feature])\n",
    "    X_test_LEncoder[feature] = label_encoder.transform(X_test_LEncoder[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_LEncoder.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "X_train_OHEncoder = X_train.copy()\n",
    "X_test_OHEncoder= X_test.copy()\n",
    "\n",
    "for feature in cat_features:\n",
    "    # Appliquer OneHotEncoder et convertir en DataFrame\n",
    "    encoded_train = one_hot_encoder.fit_transform(X_train[[feature]])\n",
    "    encoded_test = one_hot_encoder.transform(X_test[[feature]])\n",
    "    \n",
    "    # Obtenir les noms des colonnes encodées\n",
    "    encoded_columns = one_hot_encoder.get_feature_names_out([feature])\n",
    "    \n",
    "    # Créer des DataFrames pour les features encodées sans réinitialiser les index\n",
    "    encoded_train_df = pd.DataFrame(encoded_train, columns=encoded_columns, index=X_train.index)\n",
    "    encoded_test_df = pd.DataFrame(encoded_test, columns=encoded_columns, index=X_test.index)\n",
    "    \n",
    "    # Concaténer les DataFrames encodés avec les DataFrames originaux sans changer les index\n",
    "    X_train_OHEncoder = pd.concat([X_train_OHEncoder, encoded_train_df], axis=1).drop(columns=[feature])\n",
    "    X_test_OHEncoder = pd.concat([X_test_OHEncoder, encoded_test_df], axis=1).drop(columns=[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_OHEncoder.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelisation - Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise dans la suite : X_train_OHEncoder, y_train et X_test_OHEncoder, y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_OHEncoder.shape, y_train.shape, X_test_OHEncoder.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree.fit(X_train_OHEncoder, y_train)\n",
    "\n",
    "y_pred = decision_tree.predict(X_test_OHEncoder)\n",
    "evaluate.plot_confusion_matrix_sns(y_test, y_pred, \"Decision Tree\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrix\n",
    "print('='*20)\n",
    "print('Decision Tree')\n",
    "print('='*20, '\\n')\n",
    "\n",
    "print(\"Matrice de confusion:\")\n",
    "print(confusion_matrix(y_test, y_pred), '\\n') # afficher à l'écran notre matrice de confusion\n",
    "print(\"Rapport de classification:\")\n",
    "print(classification_report(y_test, y_pred), '\\n')\n",
    "print('Exactitude: %f' %(accuracy_score(y_test,y_pred)*100), '\\n')\n",
    "c_matrix = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=c_matrix) \n",
    "disp.plot() \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
